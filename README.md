## **Adaptive Optimization, Fall 2021**

#**1. Local Search Algorithms**

Based on the below well-known Rosenbrck function, try to apply several search algorithms and find the optimal solution using three local search algorithms. 

min f(x,y)=(1-x)^2+〖100(y-x^2 )〗^2
 
![image](https://github.com/YoonDosik/Metaheuristics/assets/144199897/cc4038d3-ca97-4e30-a138-d7552a607439)

	1. Gradient Ascent (Decent) Search
	2. Newton method
	3. Hill-Climbing

After apply three algorithms using Python, compare the performance among the algorithms.

-------------

#**2. Local Search Algorithms**

1) natural real solution representation and 2) binary encoded solution representation 

The numerical example of unconstrained optimization problem in Chap 1.2 from Gen & Cheng book is given as follows:

![image](https://github.com/YoonDosik/Metaheuristics/assets/144199897/ee107995-e356-4aaa-a206-c35940a86bbb)

	1. Define two kinds of “neighbor-hood” using in your algorithm. Then, apply those to 2).
	2. Develop a neighbor-hood local search (NH-LS) algorithm using 1) natural real solution representation and 2) binary encoded solution representation.
